\documentclass[11pt,a4paper]{article}

\usepackage{fullpage}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{subcaption}


\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\usepackage{todonotes}                %% notes from the authors

\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\fancypagestyle{firstpagefooter} {
	\lfoot{\tiny{Version: 25.09.2018}}
	\cfoot{}
	\rfoot{\thepage}
	
}

\lfoot{Name: Philip Junker Legi: 13-913-389}
\rfoot{\thepage}

\begin{document}

\title{Advanced Systems Lab Report\\ \normalsize{Autumn Semester 2018}}
\author{Name: Philip Junker\\Legi: 13-913-389}
\date{
	\vspace{4cm}
	\textbf{Grading} \\
	\vspace{0.5cm}
	\begin{tabular}{|c|c|}
		\hline  \textbf{Section} & \textbf{Points} \\
		\hline  1                &                 \\ 
		\hline  2                &                 \\ 
		\hline  3                &                 \\ 
		\hline  4                &                 \\ 
		\hline  5                &                 \\ 
		\hline  6                &                 \\ 
		\hline  7                &                 \\ 
		\hline \hline Total      &                 \\
		\hline 
	\end{tabular} 
}
\maketitle
\thispagestyle{firstpagefooter}

\newpage

\section{System Overview (75 pts)}

% Describe the implementation of your system and highlight design decisions relevant for the experiments. 
My middleware is implemented as a consumer / producer system. 
It has a single networking thread, the producer, which accepts incoming requests and puts it into the queue.
On the other hand it has a configurable amount of worker threads, the consumers, which consume the queue.
They are connected via a Java BlockingQueue. For this implementation I chose the LinkedBlockingQueue implementation because it provides thread safety, separate read and write locks and no maximum capacity.
All threads are created and started by the main thread.
In addition, the main thread also creates the request queue and registers a shutdown hook, which assures that all logfiles are written before the system terminates on a SIGTERM signal.
% TODO: create system overview illustration and refer to it

The networker thread handles the incoming connections from the clients and performs a minimal request parsing to determine whether a request is complete and therefore ready to be processed.
For this, the networker uses Java's non-blocking I/O (NIO) mechanisms to set up an event polling loop over all connected sockets in its run method.
A Selector, which is responsible to efficiently poll many file descriptors, is used to accept and register new connections.
The networker thread reads any connected socket that becomes readable.
An empty request structure is initialized during setup of a connection and stored using the Selector's attachment mechanism provided by Java NIO.
The request structure, which is being discussed in more detail in the next paragraph, is used to parse and buffer incoming requests over the connection it is attached to and to store logs related to a request.

% Explain how messages are parsed 
Requests might arrive in multiple packets and therefore might not be complete within a single socket read operation.
To make sure only complete requests are forwardet to the worker threads, the networker thread maintains a single request structure per connection into which incoming data is buffered until the request is complete.
A single request structure per connection is sufficient because the system is closed, meaning clients wait until their previous request has been answered before sending the next one.
This design choice leads to a minimum number of request object allocations and because request objects are being reused the garbage collector is only needed on system shutdown.
Because of the closedness of the system no synchronization on the request object is necessary, even though it is being shared between networker and worker thread, as long as the worker never uses the object after the response has been sent to the client.

Detecting whether a request is complete is done in a very simple way in order to reduce the work done in the networker thread.
The isComplete function only checks whether the last byte of the buffer is equal to a newline character.
The rest of the parsing is then done inside the worker thread. By checking the first character in the buffer, the worker thread determines whether it is a get or a set request.
Furthermore, if it is a get request, it parses the other arguments to determine whether it is a multiget (more than 1 key) or a get request (exactly 1 key).
For a set request no further parsing is required, because it can be forwarded as it is to the memcached servers.
During the parsing the buffer data is never being copied during a normal run, neither into other buffers or into String objects.
The only exception is in case an error occurs to make it easier to trace the error, and in this case the performance is not the main target anymore.
To achieve this, the request object only maintains a list of offsets which indicate the position of space and newline characters in the header of the request.
In sharding mode, the offsets will be used by the worker handling the request to create byte buffer slices for each key range.

Each worker thread continuously reads blockingly from the queue in its run method.
Once it gets a request, it parses its type and then chooses the correct function to handle it (handleGet, handleMultiget, handleSet).
In case sharded mode is deactivated, handleMultiget is equivalent to handleGet.
Get and non-sharded multiget requests are load balanced among all connected memcached servers using a round-robin scheme.
To avoid a shared token amongst the workers, each worker maintains its own counter which is initialized by the main thread in a way that the worker threads are spread out evenly among the servers and vice versa.
Whenever a worker thread wants to access a server it uses the current counter value modulo the number of memcached server is used as an index to a list storing the server connections.
On every balanced operation, the worker increases its counter.
In expectation, this guarantees an even distribution of load, whitout incurring any coordination or hashing overhead.
Sharded multiget requests are balanced similarly. In this setting a worker thread splits the keys into equally sized portions and sents each portion to one server, starting with its current round-robin index.
Because the sharding scheme is a simple division, this leads to one server receiving one key more or less than the others.
In expectation, this imbalance is avoided by choosing the starting server using the round-robin scheme and increasing the current round-robin index afterwards by the number of servers used.
Each worker thread communicates blockingly with each server by sending requests and receiving responses one after another.
Therefore the time to serve a sharded multiget request is at least as long as the slowest server requires to respond.
For this project, non-blocking schemes were not considered in order to reduce complexity and keep service time analysis simple.
Set requests are not load balanced but replicated to every server to the middleware.
Again, replication is handled in a blocking way by forwarding the request to each server one after another.

% explain how statistics are gathered in a multi-threaded setting. 
During the handling of a request in the middleware, various meta data is being attached to it, such as time and queue size when the request entered the middleware, number of cache misses, waiting time in queue, service time on memcached servers, total time spent in middleware and information about which servers have been contacted to service this request.
This meta data is used to log statistics about the processed requests.
The middleware logs into two files using the log4j2 library, one file for errors and one for aggregated request statistics.
The error file is synchronized, in order to not lose information in case of a crash.
The requests file is buffered and only flushed to file at the shutdown of the system if the buffer limit of 10MB is not reached (for the experiments taken for this report, the file has always been flushed at shutdown).
According to the log4j2 documentation, its file appenders are synchronized and hence safe to use in a multi thread environment like the one presented here (with multiple worker threads logging infos about threads possibly simultaneously).

In order to avoid massive amounts of log data I decided to do a lightweight aggregation inside my middleware.
Every worker thread receives the same starting timestamp as well as the desired granularity of aggregation at creation which it uses to initialize its AggregationLogger.
Whenever a request is finished for a worker thread, it hands the request object to its AggregationLogger.
The AggregationLogger checks if the request timestamp at hand is in the current time window.
If that's the case, the AggregationLogger will add the meta data of the request at hand to its sums.
If not, it will write the aggregated data of the current time window and set the new period start time such that the request timestamp is in the curren time window (this is done by increasing the current start time by the desired granularity, e.g. 1s).
The AggregationLogger only writes sums to the log, which means there are no errors in the aggregation data from e.g. division.
In the aggregated log data there is one entry per second for every worker.
To merge this data into one entry per second, the python script 'postprocessing.py' is used.

To account for the startup and the cooldown phase, the first 5 seconds and the last 4 seconds of each log were dropped, to account for warmup and cooldown phase respectively.
These durations were empirically determined by looking plots showing the performance of the middleware over time for various configurations.
All aggregation windows are then aggregated into an overall per-run aggregate.
For experiments with multiple middlewares, the log files of the middlewares are aggregated (using 'postprocessing.py') before creating the overall per-run aggregate.
This is done for all three runs of each experiment, then averages and standard deviation are calculated.
The results are then stored in the $aggregated_avg$ directory from which plots were generated.
The chosen aggregation approach discards information about standard deviations on the 1 second window of the aggregated log.
This is assumed to be acceptable for the setup of this project, because it matches the format in which memtier provides the information as well as we are mainly interested in showing that the obtained results hold across multiple runs.




% Provide figures containing all the threads and queues in your system (including the network and the memcached servers). 
% Include illustrations that show how requests of different types are handled (e.g., components involved in processing the request and method calls). 
% Please include all details necessary to understand artifacts and effects in your experiments that arise from your implementation choices.

\section{Baseline without Middleware (75 pts)}

\subsection{One Server}

In this section, the maximum capacity of a single memcached server is examined. The measured throughput is presented as the total accumulated throughput from all three client machines. The number of clients is equal to the total number of virtual clients across all three client machines. All results in this section are based on the output of memtier, which provides per second averages per virtual client. The first and last three seconds of each of the three repetitions were cut off as startup and cooldown time, leaving 60 seconds of data per repetition. All plots show averages and standard deviations across three repetitions of each configuration. The sanity of the data was checked with the interactive law for both throughput and response time separately and it was found that the interactive law aligns with the measured data. The configurations are shown in the table below.

\begin{center}
	\scriptsize{
		\begin{tabular}{|l|c|}
			\hline Number of servers                        & 1                                 \\ 
			\hline Number of client machines                & 3                                 \\ 
			\hline Instances of memtier per machine         & 1                                 \\ 
			\hline Threads per memtier instance             & 2                                 \\
			\hline Virtual clients per thread (write-only)  & [1,3,6,12,20,32]                  \\ 
			\hline Virtual clients per thread (read-only)   & [1,2,3,4,5,6,32]                  \\ 
			\hline Workload                                 & Write-only and Read-only          \\
			\hline Repetitions                              & 3                                 \\ 
			\hline 
		\end{tabular}
	} 
\end{center}

\begin{figure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/2_1_throughput.eps}
        \caption{Throughput}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/2_1_latency.eps}
        \caption{Response Time}
    \end{subfigure}
    \caption{Baseline without Middleware and one Server}
    \label{fig:2-1}
\end{figure}

\begin{table}
    \begin{center}
        \scriptsize{
          \begin{tabular}{|ccc|}
            \hline
            \textbf{Client} & \textbf{Middleware} & \textbf{Server}\\
            25.1 MB/s & 100.0 MB/s & 12.6 MB/s\\
            \hline
          \end{tabular}
        }
      \caption{Network Capacities (outgoing), measured using iperf}
      \label{link-caps}
    \end{center}
\end{table}

\subsubsection{Explanation}
%Describe in which phase the memcached servers are under-saturated, saturated, or over-saturated. Describe how throughput and response time correlate. Explain what further conclusions can be drawn from the experiment.
For read-only workload, the large value size of 4096 bytes causes GET responses to fully exhaust the outgoing capacity of the server's network link, while the CPU remains underutilized. Clearly, the bottleneck lies on the network capabilities, namely the upload, of the single memcached server. The collected dstat data shows an average upload of 12.41MB/s already for the first configuration with 6 virtual clients in total (see \autoref{dstat:2-1}). Because this value is very close to the maximum outgoing link capacity of the server machines shown in \autoref{link-caps}, which was measured using iperf, we can conclude that this indeed is the bottleneck in this system for read-only workload. The system is already with 6 virtual clients in total saturated because of the above mentioned bottleneck.

For write-only workload, the request size is large compared to the server response. The outgoing link capacity of the server should therefore not be the problem anymore. And indeed, this time outgoing network activities for both client and server machines stayed within their outgoing link capacities. However, for the memcached server a CPU utilization of 96\% has been measured for 32 virtual clients per thread as shown in \autoref{dstat:2-1} b). Clearly, the  bottleneck for the write-only workload is cpu bound on the memcached server side.
Up until 120 virtual clients in total the system  is under-saturated because with a higher amount of virtual clients the throughput increases until this point. After that point the system is in the saturation phase where the throughput stays the same while the response time increases linearly with more virtual clients.

The over-saturated phase has not been reached for both read and write-only during the experiments, this conclusion comes from the fact that only a linear increase of response time has been observed for an increasing amount of clients.

\begin{center}
    \begin{table}
    	\begin{tabular}{|l|p{2cm}|p{2cm}|p{4cm}|}
            \hline \textbf{Configuration} & \textbf{CPU} & \textbf{Send} & \textbf{Receive}\\
            \hline Server, read-only, 6 memtier clients in total & 11.0\%         & 12.41 MB/s    & 0.44 MB/s\\
            \hline Clients, read-only, 6 memtier clients in total & 5.44\%           & 0.16 MB/s     & 4.24 MB/s\\
            \hline Server, write-only,  120 memtier clients in total & 93.28\%        & 2.05 MB/s     & 63.33 MB/s\\
            \hline Clients, write-only, 120 memtier clients in total & 18.09\%       & 20.97 MB/s     & 0.69 MB/s\\
            \hline
    	\end{tabular}
	\caption{Machine Stats during Experiment 2.1}
    \label{dstat:2-1}
	\end{table}
\end{center}

\subsection{Two Servers}
In this section, the maximum load generation capacity of a single memtier instance is examined. The measured throughput is presented as the total accumulated throughput of both memtier threads. The number of clients is equal to the total number of virtual clients across all three client machines. All results in this section are based on the output of memtier, which provides per second averages per virtual client. The first and last three seconds of each of the three repetitions were cut off as startup and cooldown time, leaving 60 seconds of data per repetition. All plots show averages and standard deviations across three repetitions of each configuration. The sanity of the data was checked with the interactive law for both throughput and response time separately and it was found that the interactive law aligns with the measured data. The configurations are shown in the table below.

\begin{center}
	\scriptsize{
		\begin{tabular}{|l|c|}
			\hline Number of servers                        & 2                        \\ 
			\hline Number of client machines                & 1                        \\ 
			\hline Instances of memtier per machine         & 2                        \\ 
			\hline Threads per memtier instance             & 1                        \\
			\hline Virtual clients per thread (write-only)  & [1,3,6,12,20,32]         \\ 
			\hline Virtual clients per thread (read-only)   & [1,2,3,4,5,6,32]         \\ 
			\hline Workload                                 & Write-only and Read-only \\
			\hline Repetitions                              & 
			3                        \\ 
			\hline 
		\end{tabular}
	} 
\end{center}

\begin{figure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/2_2_throughput.eps}
        \caption{Throughput}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/2_2_latency.eps}
        \caption{Response Time}
    \end{subfigure}
    \caption{Baseline without Middleware and two Servers}
    \label{fig:2-2}
\end{figure}
\subsubsection{Explanation}

%Describe how this experiment compares to the previous section. Which results are the same and which ones differ? Explain what further conclusions can be drawn from the experiment.
For both read-only and write-only workload the system is under-saturated up until 6 virtual clients in total. This is derived from the fact that throughput is increasing significantly while the response time increases linearly in this phase. From 6 virtual clients on, the throughput does not increase at all for read-only and only very little for write-only workload while the response time continues to increase linearly for both. Hence from 6 virtual clients on the system is in saturation phase for both read-only and write-only workload. No over-saturation has been observed for both workload types.

For the read-only workload the bottleneck is again at the server, namely the outgoing network capacity. As can be seen in \autoref{dstat:2-2} (a) the server reaches an average outgoing network traffic of 12.47MB/s for 6 virtual memtier clients in total. This is very close to the previously presented maximum outgoing network capacity of the server machines (12.6MB/s) (see \autoref{link-caps}). Therefore, the system is saturated from 6 virtual memtier clients on. Before this point, the system is under-saturated for read-only workload.  An over-saturation has not been observed during the experiment. 

For the write-only workload the bottleneck has been identified at the outgoing network capacity of the single memtier client. As shown in \autoref{dstat:2-2} (d) the client reaches an average outgoing network traffic of 24.80MB/s for 12 virtual memtier clients in total. This is very close to the maximum outgoing network capacity of the client machines (25.1MB/s) presented \autoref{link-caps}. Even though the increase of throughput is very little from 6 virtual clients to 12 virtual clients, the outgoing network traffic measured at the client machine for 6 virtual clients was 24.2MB/s which still is 0.9MB/s away from the measured maximum. This is the reason the beginning of the saturation phase starts only at 12 virtual clients for write-only workload and the maximum throughput is measured with 12 virtual clients. Before this point the system is under-saturated. An over-saturation has not been observed during the experiment.

\begin{center}
    \begin{table}
    	\begin{tabular}{|l|p{2cm}|p{2cm}|p{4cm}|}
            \hline \textbf{Configuration} & \textbf{CPU} & \textbf{Send} & \textbf{Receive}\\
            \hline Server, read-only, 8 memtier clients in total & 11.40\%         & 12.45 MB/s    & 0.44 MB/s\\
            \hline Clients, read-only, 8 memtier clients in total & 21.34\%           & 0.87 MB/s     & 24.95 MB/s\\
            \hline Server, write-only,  6 memtier clients in total & 12.50\%        & 0.42 MB/s     & 12.88 MB/s\\
            \hline Clients, write-only, 6 memtier clients in total & 17.91\%       & 24.66 MB/s     & 0.83 MB/s\\
            \hline
    	\end{tabular}
	\caption{Machine Stats during Experiment 2.2}
    \label{dstat:2-2}
	\end{table}
\end{center}



\subsection{Summary}

Based on the experiments above, fill out the following table:

\begin{center}
	{Maximum throughput of different VMs.}
	\begin{tabular}{|l|p{2cm}|p{2cm}|p{4cm}|}
		\hline                        & Read-only workload [req/s] & Write-only workload [req/s] & Configuration gives max. throughput \\ 
		\hline One memcached server   &          2937          &      14791               &            read-only: 6 virtual clients \newline write-only: 120 virtual clients                         \\ 
		\hline One load generating VM &        5847            &          5943           &         read-only: 8 virtual clients \newline write-only: 6 virtual clients                            \\ 
		\hline 
	\end{tabular}
\end{center}


Write at least two paragraphs about how both results relate. Describe what is the bottleneck of this setup is. If the maximum throughput for both experiments is the same, explain why. If it is not the case, explain why not. Write down key take-away messages about the behaviour of the memtier clients and the memcached servers.

\section{Baseline with Middleware (90 pts)}

In this set of experiments, you will have to use 1 load generator VM and 1 memcached server, measuring how the throughput of the system changes when increasing the number of clients. Scaling virtual clients inside memtier has to be done as explained in the previous sections. Plot both throughput and response time as measured on the middleware.

\subsection{One Middleware}

Connect one load generator machine (one instance of memtier with CT=2) to a single middleware and use 1 memcached server. Run a read-only and a write-only workload with increasing number of clients (between 2 and 64) and measure response time \emph{both at the client and at the middleware}, and plot the throughput and response time measured in the middleware.

Repeat this experiment for different number of worker threads inside the middleware: 8, 16, 32, 64.

\begin{center}
	\scriptsize{
		\begin{tabular}{|l|c|}
			\hline Number of servers                & 1                        \\ 
			\hline Number of client machines        & 3                        \\ 
			\hline Instances of memtier per machine & 1                        \\ 
			\hline Threads per memtier instance     & 2                        \\
			\hline Virtual clients per thread       & [1..32]                  \\ 
			\hline Workload                         & Write-only and Read-only \\
			\hline Multi-Get behavior               & N/A                      \\
			\hline Multi-Get size                   & N/A                      \\
			\hline Number of middlewares            & 1                        \\
			\hline Worker threads per middleware    & [8..64]                  \\
			\hline Repetitions                      & 3 or more (at least 1 minute each)                \\ 
			\hline 
		\end{tabular}
	} 
\end{center}

\begin{figure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/3_1a_throughputMiddleware.eps}
        \caption{Throughput, read only}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/3_1b_throughputMiddleware.eps}
        \caption{Throughput, write only}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/3_1a_latencyMiddleware.eps}
        \caption{Response Time, read only}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/3_1b_latencyMiddleware.eps}
        \caption{Response Time, write only}
    \end{subfigure}

    \caption{Baseline with one Middleware, one Server}
    \label{fig:3-1}
\end{figure}

\subsubsection{Explanation}

Provide a detailed analysis of the results (e.g., bottleneck analysis, component utilizations, average queue lengths, system saturation). Add any additional figures and experiments that help you illustrate your point and support your claims.

\subsection{Two Middlewares}

Connect one load generator machine (two instances of memtier with CT=1) to two middlewares and use 1 memcached server. Run a read-only and a write-only workload with increasing number of clients (between 2 and 64) and measure response time \emph{both at the client and at the middleware}, and plot the throughput and response time as measured in the middleware.

Repeat this experiment for different number of worker threads inside the middleware: 8, 16, 32, 64.

If in your experiment the middleware is not the bottleneck, repeat the experiment that reaches the highest throughput but using two load generator VMs (each with 2x memtier CT=1) instead of one. Otherwise, explain how you know that the middlewares are the limiting factor in terms of throughput.

\begin{center}
	\scriptsize{
		\begin{tabular}{|l|c|}
			\hline Number of servers                & 1                        \\ 
			\hline Number of client machines        & 3                        \\ 
			\hline Instances of memtier per machine & 2                        \\ 
			\hline Threads per memtier instance     & 1                        \\
			\hline Virtual clients per thread       & [1..32]                  \\ 
			\hline Workload                         & Write-only and Read-only \\
			\hline Multi-Get behavior               & N/A                      \\
			\hline Multi-Get size                   & N/A                      \\
			\hline Number of middlewares            & 2                        \\
			\hline Worker threads per middleware    & [8..64]                  \\
			\hline Repetitions                      & 3 or more (at least 1 minute each)                \\ 
			\hline 
		\end{tabular}
	} 
\end{center}

\begin{figure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/3_2a_throughputMiddleware.eps}
        \caption{Throughput, read only}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/3_2b_throughputMiddleware.eps}
        \caption{Throughput, write only}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/3_2a_latencyMiddleware.eps}
        \caption{Response Time, read only}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \includegraphics[width=1\linewidth]{plots/3_2b_latencyMiddleware.eps}
        \caption{Response Time, write only}
    \end{subfigure}

    \caption{Baseline with two Middlewares, one Server}
    \label{fig:3-2}
\end{figure}

\subsubsection{Explanation}

Provide a detailed analysis of the results (e.g., bottleneck analysis, component utilizations, average queue lengths, system saturation). Add any additional figures and experiments that help you illustrate your point and support your claims.

\subsection{Summary}

Based on the experiments above, fill out the following table. For both of them use the numbers from a single experiment to fill out all lines. Miss rate represents the percentage of GET requests that return no data. Time in the queue refers to the time spent in the queue between the net-thread and the worker threads.


\begin{center}
	{Maximum throughput for one middleware.}
	\begin{tabular}{|l|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
		\hline                                & Throughput & Response time & Average time in queue & Miss rate \\ 
		\hline Reads: Measured on middleware  &            &               &                       &           \\ 
		\hline Reads: Measured on clients     &            &               & n/a                   &           \\ 
		\hline Writes: Measured on middleware &            &               &                       & n/a       \\ 
		\hline Writes: Measured on clients    &            &               & n/a                   & n/a       \\ 
		\hline 
	\end{tabular}
\end{center}

\begin{center}
	{Maximum throughput for two middlewares.}
	\begin{tabular}{|l|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
		\hline                                & Throughput & Response time & Average time in queue & Miss rate \\ 
		\hline Reads: Measured on middleware  &            &               &                       &           \\ 
		\hline Reads: Measured on clients     &            &               & n/a                   &           \\ 
		\hline Writes: Measured on middleware &            &               &                       & n/a       \\ 
		\hline Writes: Measured on clients    &            &               & n/a                   & n/a       \\ 
		\hline 
	\end{tabular}
\end{center}

Based on the data provided in these tables, write at least two paragraphs summarizing your findings about the performance of the middleware in the baseline experiments.

\section{Throughput for Writes (90 pts)}

\subsection{Full System}

Connect three load generating VMs to two middlewares and three memchached servers. Run a write-only experiment. 
You need to plot throughput and response time measured on the middleware as a function of number of clients. The measurements have to be performed for 8, 16, 32 and 64 worker threads inside each middleware.

\begin{center}
	\scriptsize{
		\begin{tabular}{|l|c|}
			\hline Number of servers                & 3          \\ 
			\hline Number of client machines        & 3          \\ 
			\hline Instances of memtier per machine & 2          \\ 
			\hline Threads per memtier instance     & 1          \\
			\hline Virtual clients per thread       & [1..32]    \\ 
			\hline Workload                         & Write-only \\
			\hline Multi-Get behavior               & N/A        \\
			\hline Multi-Get size                   & N/A        \\
			\hline Number of middlewares            & 2          \\
			\hline Worker threads per middleware    & [8..64]    \\
			\hline Repetitions                      & 3 or more (at least 1 minute each)  \\ 
			\hline 
		\end{tabular}
	} 
\end{center}

\subsubsection{Explanation}

Provide a detailed analysis of the results (e.g., bottleneck analysis, component utilizations, average queue lengths, system saturation). Add any additional figures and experiments that help you illustrate your point and support your claims.

\subsection{Summary}

Based on the experiments above, fill out the following table with the data corresponding to the maximum throughput point for all four worker-thread scenarios.

\begin{center}
	{Maximum throughput for the full system}
	\begin{tabular}{|l|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
		\hline                                            & WT=8 & WT=16 & WT=32 & WT=64 \\ 
		\hline Throughput (Middleware)                    &      &       &       &       \\ 
		\hline Throughput (Derived from MW response time) &      &       &       &       \\ 
		\hline Throughput (Client)                        &      &       &       &       \\ 
		\hline Average time in queue                      &      &       &       &       \\ 
		\hline Average length of queue                    &      &       &       &       \\ 
		\hline Average time waiting for memcached         &      &       &       &       \\ 
		\hline 
	\end{tabular}
\end{center}

Based on the data provided in these tables, draw conclusions on the state of your system for a variable number of worker threads.

\section{Gets and Multi-gets (90 pts)}

For this set of experiments you will use three load generating machines, two middlewares and three memcached servers. Each memtier instance should have 2 virtual clients in total and the number of middleware worker threads is 64, or the one that provides the highest throughput in your system (whichever number of threads is smaller).

For multi-GET workloads, memtier will generate a mixture of SETs, GETs, and multi-GETs. Memtier only allows to specify the maximum number of keys in a multi-GET request. Therefore, be aware that requests can also contain fewer keys than the provided value. It is recommended to record the average size of the multi-GETs. You will have to measure response time on the client as a function of multi-get size, with and without sharding on the middlewares.

\subsection{Sharded Case}

Run multi-gets with 1, 3, 6 and 9 keys (memtier configuration) with sharding enabled (multi-gets are broken up into smaller multi-gets and spread across servers). Plot average response time as measured on the client, as well as the 25th, 50th, 75th, 90th and 99th percentiles.

\begin{center}
	\scriptsize{
		\begin{tabular}{|l|c|}
			\hline Number of servers                & 3                       \\ 
			\hline Number of client machines        & 3                       \\ 
			\hline Instances of memtier per machine & 2                       \\ 
			\hline Threads per memtier instance     & 1                       \\
			\hline Virtual clients per thread       & 2     		            \\ 
			\hline Workload                         & ratio=1:$<$Multi-Get size$>$             \\
			\hline Multi-Get behavior               & Sharded                 \\
			\hline Multi-Get size                   & [1..9]                  \\
			\hline Number of middlewares            & 2                       \\
			\hline Worker threads per middleware    & max. throughput config. \\
			\hline Repetitions                      & 3 or more (at least 1 minute each)               \\ 
			\hline 
		\end{tabular}
	} 
\end{center}

\subsubsection{Explanation}

Provide a detailed analysis of the results (e.g., bottleneck analysis, component utilizations, average queue lengths, system saturation). Add any additional figures and experiments that help you illustrate your point and support your claims.

\subsection{Non-sharded Case}

Run multi-gets with 1, 3, 6 and 9 keys (memtier configuration) with sharding disabled. Plot average response time as measured on the client, as well as the 25th, 50th, 75th, 90th and 99th percentiles.

\begin{center}
	\scriptsize{
		\begin{tabular}{|l|c|}
			\hline Number of servers                & 3                       \\ 
			\hline Number of client machines        & 3                       \\ 
			\hline Instances of memtier per machine & 2                       \\ 
			\hline Threads per memtier instance     & 1                       \\
			\hline Virtual clients per thread       & 2                		 \\ 
			\hline Workload                         & ratio=1:$<$Multi-Get size$>$              \\
			\hline Multi-Get behavior               & Non-Sharded             \\
			\hline Multi-Get size                   & [1..9]                  \\
			\hline Number of middlewares            & 2                       \\
			\hline Worker threads per middleware    & max. throughput config. \\
			\hline Repetitions                      & 3 or more (at least 1 minute each)               \\ 
			\hline 
		\end{tabular}
	} 
\end{center}

\subsubsection{Explanation}

Provide a detailed analysis of the results (e.g., bottleneck analysis, component utilizations, average queue lengths, system saturation). Add any additional figures and experiments that help you illustrate your point and support your claims.

\subsection{Histogram}

For the case with 6 keys inside the multi-get, display four histograms representing the sharded and non-sharded response time distribution, both as measured on the client, and inside the middleware. Choose the bucket size in the same way for all four, and such that there are at least 10 buckets on each of the graphs.

\subsection{Summary}

Provide a detailed comparison of the sharded and non-shareded modes. For which multi-GET size is sharding the preferred option? Provide a detailed analysis of your system. Add any additional figures and experiments that help you illustrate your point and support your claims.

\section{2K Analysis (90 pts)}

For 3 client machines (with 64 total virtual clients per client VM) measure the throughput and response time of your system in a 2k experiment with repetitions. All GET operations have a single key. Investigate the following parameters:

\begin{itemize}
		
	\item Memcached servers: 1 and 3
	\item Middlewares: 1 and 2
	\item Worker threads per MW: 8 and 32
	      	      
\end{itemize}

Repeat the experiment for (a)~a write-only and (b)~a read-only workload.
For each of the two workloads, what is the impact of these parameters on throughput, respectively response time?

\begin{center}
	\scriptsize{
		\begin{tabular}{|l|c|}
			\hline Number of servers                & 1 and 3                                     \\ 
			\hline Number of client machines        & 3                                           \\ 
			\hline Instances of memtier per machine & 1 (1 middleware) or 2 (2 middlewares) \\ 
			\hline Threads per memtier instance     & 2 (1 middleware) or 1 (2 middlewares)   \\
			\hline Virtual clients per thread       &  32                                     \\ 
			\hline Workload                         & Write-only and Read-only\\
			\hline Multi-Get behavior               & N/A                                         \\
			\hline Multi-Get size                   & N/A                                         \\
			\hline Number of middlewares            & 1 and 2                                     \\
			\hline Worker threads per middleware    & 8 and 32                                    \\
			\hline Repetitions                      & 3 or more (at least 1 minute each)                                   \\ 
			\hline 
		\end{tabular}
	} 
\end{center}

\section{Queuing Model (90 pts)}

Note that for queuing models it is enough to use the experimental results from the previous sections. It is, however, possible that the numbers you need are not only the ones in the figures we asked for, but also the internal measurements that you have obtained through instrumentation of your middleware.

\subsection{M/M/1}

Build queuing model based on Section 4 (write-only throughput) for each worker-thread configuration of the middleware. Use one M/M/1 queue to model your entire system. Motivate your choice of input parameters to the model. Explain for which experiments the predictions of the model match and for which they do not.

\subsection{M/M/m}

Build an M/M/m model based on Section 4, where each middleware worker thread is represented as one service.  Motivate your choice of input parameters to the model. Explain for which experiments the predictions of the model match and for which they do not.

\subsection{Network of Queues}

Based on Section 3, build a network of queues which simulates your system. Motivate the design of your network of queues and relate it wherever possible to a component of your system. Motivate your choice of input parameters for the different queues inside the network. Perform a detailed analysis of the utilization of each component and clearly state what the bottleneck of your system is. Explain for which experiments the predictions of the model match and for which they do not.

\end{document}
